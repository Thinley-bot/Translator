{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Thinley-bot/Translator/blob/main/Dzo2Env3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLUSeiIY-PlT"
      },
      "source": [
        "# This is the first version of neural machine translation using the encoder decoder and keras libraries. ⚓"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lr7sqNZV1QhH",
        "outputId": "07e3138d-1c28-47c4-a87e-efb38df99d03"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7lJG3BY6elI",
        "outputId": "535381ae-166c-48d8-9514-77319a713718"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.11.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "C2AnDbip6sOc"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import re\n",
        "from numpy import array, argmax, random, take\n",
        "import numpy as np\n",
        "from numpy.random import shuffle\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import pad_sequences\n",
        "from keras.models import load_model\n",
        "from keras import optimizers\n",
        "from keras.layers import TimeDistributed\n",
        "import matplotlib.pyplot as plt\n",
        "from pickle import dump\n",
        "from unicodedata import normalize\n",
        "from keras.models import load_model\n",
        "import unicodedata\n",
        "import pickle as pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qUcVhdJB627h"
      },
      "outputs": [],
      "source": [
        "# Defining the path to the raw data set\n",
        "fileurl = '/content/drive/MyDrive/Final Year Project/eng-dzo.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pfLWAUf-7xYi"
      },
      "outputs": [],
      "source": [
        "# function to read raw text file\n",
        "def read_text(filename):\n",
        "    # open the file\n",
        "    file = open(filename, mode='rt', encoding='utf-8')\n",
        "    # read all text\n",
        "    text = file.read()\n",
        "    \n",
        "    # Split the text into individual lines\n",
        "    lines = text.strip().split('\\n')\n",
        "    # Splitting each line based on tab spaces and creating a list\n",
        "    lines = [line.split('\\t') for line in lines]\n",
        "\n",
        "    file.close()\n",
        "    return array(lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHR1i9sP72mJ",
        "outputId": "ca2bfe0d-5227-4b6d-9201-55ee3e78acb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['They smiled at one another.',\n",
              "        'ཁོང་ ཚུ་ གཅིག་གིས་གཅིག་ལུ་ བལྟ་ སྟེ་ དགའ་འཛུམ་ སྟོན་ ནུག །'],\n",
              "       ['They want to do this right.',\n",
              "        'ཁོང་ ཚུ་ གིས་ ཨ་ནཱི་ དྲང་པོ་ སྦེ་ འབད་ ནི་ མས །'],\n",
              "       ['They want to do this right away.',\n",
              "        'ཁོང་ ཚུ་ གིས་ ཨ་ནཱི་ འདི་འཕྲོ་ལས་ འབད་ ནི་ མས །'],\n",
              "       ['They watched me in silence.',\n",
              "        'ཁོང་ ཚུ་ གིས་ ང་ ལུ་ ཁུ་སིམ་སི་ སྦེ་ བལྟ་ སྡོད་ ནུག །'],\n",
              "       ['They water the fruit trees.',\n",
              "        'ཁོང་ ཚུ་ གིས་ ཤིང་འབྲས་ ཀྱི་ ཤིང་ ནང་ ཆུ་ བླུགས་ ནུག །'],\n",
              "       ['They were acting strangely.',\n",
              "        'ཁོང་ ཚུ་ གིས་ ཧ་གོ་ མ་ ཚུགས་ པའི་ རྣམ་འགྱུར་ སྟོན་ མས །'],\n",
              "       ['They were born in Thailand.',\n",
              "        'ཁོང་ ཚུ་ ཐའི་ལེནཌ་ ལུ་ སྐྱེས་ ནུག །'],\n",
              "       ['They were tired of waiting.',\n",
              "        'ཁོང་ ཚུ་ སྒུག་ སྟེ་ ར་ སྡོད་ དེ་ འུ་སྡུག་ ནུག །'],\n",
              "       ['They were tired of watching.',\n",
              "        'ཁོང་ ཚུ་ བལྟ་ སྟེ་ ར་ སྡོད་ དེ་ འུ་སྡུག་ ནུག །'],\n",
              "       ['They were tired of walking.',\n",
              "        'ཁོང་ ཚུ་ ལམ་འགྱོ་ སྟེ་ ར་ སྡོད་ དེ་ འུ་སྡུག་ ནུག །']],\n",
              "      dtype='<U251')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Reading the data using the function\n",
        "mtData = read_text(fileurl)\n",
        "# Taking only 50000 rows of data\n",
        "mtData = mtData[:50000,:2]\n",
        "print(mtData.shape)\n",
        "mtData[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PcHEpTeb8smu"
      },
      "outputs": [],
      "source": [
        "def unicode_to_ascii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "def preprocess_english(s):\n",
        "    s=str(s)\n",
        "    s = unicode_to_ascii(s.lower().strip())\n",
        "    s = re.sub(r\"([,.!?])\", r\" \\1 \", s)\n",
        "    s = re.sub(r\"[^a-zA-Z,.!?]+\", r\" \", s)\n",
        "    #replace the extra space by single space\n",
        "    s = re.sub(r\"\\s+\", r\" \", s)\n",
        "    return s\n",
        "def preprocess_dzongkha(s):\n",
        "  s=str(s)\n",
        "  s = re.sub(r'་\\s*[& ]', ' ',s)\n",
        "  s=re.sub(r\"\\s*།\\s*$\", '', s)\n",
        "  s=re.sub(r'\\s#\\s',' ',s)\n",
        "  return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "x1a_h2Zm76xL"
      },
      "outputs": [],
      "source": [
        "# Cleaning the document from all unwanted characters\n",
        "\n",
        "def cleanDocs(lines):\n",
        "    cleanArray = list()\n",
        "    for pair in lines:\n",
        "        cleanDocs = list()\n",
        "        # for line in pair:\n",
        "       \n",
        "            # print(line)\n",
        "        for i, line in enumerate(pair):\n",
        "            if i==0:\n",
        "                line=preprocess_english(line)\n",
        "                # print(line)\n",
        "            else:\n",
        "                line=preprocess_dzongkha(line)\n",
        "            # line = normalize('NFD', line).encode()\n",
        "            # line = line.decode('UTF-8')\n",
        "            line = line.split()\n",
        "            # line = [word.lower() for word in line]\n",
        "            # line = [word.translate(table) for word in line]\n",
        "            # line = [re_print.sub('', word) for word in line]\n",
        "            cleanDocs.append(' '.join(line))\n",
        "            # print(clean_pair)\n",
        "            \n",
        "        cleanArray.append(cleanDocs)\n",
        "    return array(cleanArray)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcHjuqzk9gcI",
        "outputId": "52741fa3-d734-46d4-effd-da75508739b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['they smiled at one another .',\n",
              "        'ཁོང ཚུ གཅིག་གིས་གཅིག་ལུ བལྟ སྟེ དགའ་འཛུམ སྟོན ནུག'],\n",
              "       ['they want to do this right .',\n",
              "        'ཁོང ཚུ གིས ཨ་ནཱི དྲང་པོ སྦེ འབད ནི མས'],\n",
              "       ['they want to do this right away .',\n",
              "        'ཁོང ཚུ གིས ཨ་ནཱི འདི་འཕྲོ་ལས འབད ནི མས'],\n",
              "       ['they watched me in silence .',\n",
              "        'ཁོང ཚུ གིས ང ལུ ཁུ་སིམ་སི སྦེ བལྟ སྡོད ནུག'],\n",
              "       ['they water the fruit trees .',\n",
              "        'ཁོང ཚུ གིས ཤིང་འབྲས ཀྱི ཤིང ནང ཆུ བླུགས ནུག'],\n",
              "       ['they were acting strangely .',\n",
              "        'ཁོང ཚུ གིས ཧ་གོ མ ཚུགས པའི རྣམ་འགྱུར སྟོན མས'],\n",
              "       ['they were born in thailand .', 'ཁོང ཚུ ཐའི་ལེནཌ ལུ སྐྱེས ནུག'],\n",
              "       ['they were tired of waiting .',\n",
              "        'ཁོང ཚུ སྒུག སྟེ ར སྡོད དེ འུ་སྡུག ནུག'],\n",
              "       ['they were tired of watching .',\n",
              "        'ཁོང ཚུ བལྟ སྟེ ར སྡོད དེ འུ་སྡུག ནུག'],\n",
              "       ['they were tired of walking .',\n",
              "        'ཁོང ཚུ ལམ་འགྱོ སྟེ ར སྡོད དེ འུ་སྡུག ནུག']], dtype='<U156')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Cleaning the sentences\n",
        "cleanMtDocs = cleanDocs(mtData)\n",
        "cleanMtDocs[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9FH2HU19lsR",
        "outputId": "6380448b-a906-4eab-b319-81c8628659c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 2)\n"
          ]
        }
      ],
      "source": [
        "# The dimensions of the data set\n",
        "len(cleanMtDocs)\n",
        "print(cleanMtDocs.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0I_5vpD956C",
        "outputId": "64d75455-fba8-4160-ae2a-b5cd388aa680"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['hand me the remote .', 'རྒྱང་རིང འདི ང ལུ སྤྲོད གནང'],\n",
              "       ['well done !', 'ལེགས་ཤོམ བཏང ནུག མས'],\n",
              "       ['i m eating lunch .', 'ང ཉི་མ་གི་ལྟོ ཟ དོ'],\n",
              "       ['karma is sweating .', 'ཀརྨ རྔུལ་ནག འཐོན དེས'],\n",
              "       ['i met a friend .', 'ང ཆ་རོགས ཆིག དང ཕྱད ཅི'],\n",
              "       ['this makes no sense to me .',\n",
              "        'འདི་གིས ང ལུ དོན་དག ག་ནི ཡང མི བཟོ བས'],\n",
              "       ['i ll show you my room .', 'ང གིས ཁྱོད ལུ ངེའི ཁང མི སྟོན གེ'],\n",
              "       ['get down from there .', 'ཕར ལས མར འབབ'],\n",
              "       ['it rained for a week .', 'བདུན་ཕྲག གཅིག ར ཆརཔ རྐྱབ ཅི'],\n",
              "       ['they have no more wine .', 'ཁོང ལུ ད ཝའིན མིན་འདུག']],\n",
              "      dtype='<U156')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Shuffling the data\n",
        "shuffle(cleanMtDocs)\n",
        "cleanMtDocs[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "TZHAa-679-Qg"
      },
      "outputs": [],
      "source": [
        "#save the clean data as pickle file\n",
        "def save_data(sentences, filename):\n",
        "    pkl.dump(sentences, open(filename, 'wb'))\n",
        "    print(f'Saved: {filename}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6ritBqs-3eG",
        "outputId": "2cef2b02-2917-4924-ef89-94ed5513cf8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: english-dzongkha.pkl\n"
          ]
        }
      ],
      "source": [
        "save_data(cleanMtDocs,'english-dzongkha.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgbLHmXN_RRR",
        "outputId": "2720fbe4-8f6b-4cf3-fc85-abaf5dd7a4b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hand me the remote . => རྒྱང་རིང འདི ང ལུ སྤྲོད གནང\n",
            "well done ! => ལེགས་ཤོམ བཏང ནུག མས\n",
            "i m eating lunch . => ང ཉི་མ་གི་ལྟོ ཟ དོ\n",
            "karma is sweating . => ཀརྨ རྔུལ་ནག འཐོན དེས\n",
            "i met a friend . => ང ཆ་རོགས ཆིག དང ཕྱད ཅི\n",
            "this makes no sense to me . => འདི་གིས ང ལུ དོན་དག ག་ནི ཡང མི བཟོ བས\n",
            "i ll show you my room . => ང གིས ཁྱོད ལུ ངེའི ཁང མི སྟོན གེ\n",
            "get down from there . => ཕར ལས མར འབབ\n",
            "it rained for a week . => བདུན་ཕྲག གཅིག ར ཆརཔ རྐྱབ ཅི\n",
            "they have no more wine . => ཁོང ལུ ད ཝའིན མིན་འདུག\n",
            "what is an off peak online only ticket ? => ཡོངས་འབྲེལ ཐོག རྐྱངམ་གཅིག ཡོད མི ཤོག་འཛིན འདི ག་ཅི སྨོ\n",
            "i would like an air conditioned room . => ང གིས སྙོམས་རླུང ཡོད པའི ཁང་མིག ཅིག དགའ ནི མས\n",
            "it s useless to try . => འབད་རྩོལ བསྐྱེད དེ ཁུངས མེད\n",
            "you can t blame me . => ཁྱོད ང ལུ རྫུན་ཁ བཀལ མི ཆོག\n",
            "i m retired . => ང དགོངས་ཞུ འབད ཡི\n",
            "how s the family ? => བཟའ་ཚང འདི ག་དེ་སྦེ ཡོད\n",
            "pick a number . => ཨང་གྲངས ཅིག འཐུ\n",
            "i still have no idea what s going on . => ག་ཅི འབདཝ ཨིན་ན ད་ལྟོ ཡང ང ལུ གནས་ཚུལ ཅིག མེད\n",
            "don t wait for me . => ང ལུ མ བསྒུག\n",
            "thanks for joining us . => ང་བཅས དང གཅིག་ཁར གྲལ་གཏོགས འབད མི ལུ བཀའ་དྲིན ཆེ\n",
            "continue your story . => ཁྱོད་རའི སྲུང་འཕྲོ་འཐུད\n",
            "cattle feed on grass . => སྒོ་ནོར་སེམས་ཅན རྩཱ ལུ སྟེན ཏེ སྡོདཔ ཨིན\n",
            "the paint s drying . => བཀྲག་རྩི འདི སྐམ དེས\n",
            "how many letters ? => ཡི་གུ ག་དེམ་ཅིག སྨོ\n",
            "i tricked you . => ང གིས ཁྱོད ལུ མགུ་སྐོར རྐྱབ ཅི\n",
            "is this your family ? => འདི ཁྱོད ཀྱི ཟ་ཚན ཨིན་ན\n",
            "you must all leave . => ཁྱེད ག་ར འཐོན འགྱོ དགོ པས\n",
            "a portfolio of project work to be proud of ! => ངལ་རངས དགོ པའི ལས་འགུལ ལཱ གི ཡིག་སྣོད\n",
            "why do you want me to stop ? => ཁྱོད ཀྱིས ག་ཅི་སྦེ ང གིས བཀག བཞག དགོཔ སྨོ\n",
            "my mouth is numb . => ངེའི ཁ་ ཚོར་བ མེདཔ ཨིན\n",
            "i won again . => ང ད་རུང རྒྱལ་སོང ཡི\n",
            "how will you pay your debts ? => ཁྱོད ཀྱིས བུ་ལོན ག་དེ་སྦེ སྤྲོད ནི སྨོ\n",
            "let me verify that . => འདི ང གིས བདེན་དཔྱད འབད གེ\n",
            "please don t go home . => ཁྱིམ ནང འབྱོན མ གནང\n",
            "i almost forgot to buy milk . => ང གིས ཨོམ ཉོ ནི བརྗེད ནི ར འབད ནུག\n",
            "it gave me the creeps . => འདི་གིས ང ལུ བ སྤུ ཟིང་ཟི འབད བཅུག ཡི\n",
            "can you get it done before the end of the week ? => ཁྱོད ཀྱིས བདུན་ཕྲག རྫོགས་མཚམས ཀྱི ཧེ་མ འདི འབད ཚརཝ ག\n",
            "i d buy that . => དེ ང གིས ཉོ ཡི\n",
            "come visit us soon in our new style hotels . => ང་བཅས ཀྱི བཟའ་ཁང བཟོ་རྣམ གསརཔ ནང མགྱོགས་པ་ར ལྟ་སྐོར ནང ཤོག\n",
            "he lives like a king . => ཁོ རྒྱལཔོ ཅིག བཟུམ་སྦེ སྡོདཔ ཨིན\n",
            "that i might touch that cheek ! => ང གིས ཨ་ཕི ཟ་ལྟབ འདོགས འོང\n",
            "you are your own boss . => ཁྱོད ཁྱོད རང གི འགོ་དཔོན ཨིན\n",
            "the trophy is pure silver and gold . => རྒྱལ་རྟགས འདི་སེར དང དངུལ ངོ་མ ཨིན མས\n",
            "karma said he was busy . => ཀརྨ གིས ཁོ དལ་ཁོམ མེད ཟེར སླབ ཅི\n",
            "a fire broke out in my neighborhood last night . => ངེ་གི ཉེ་འདབས ས་ཁོངས ནང ཁ་ཙ ནུབ་མོ མེ རྐྱེན་ཤོར ནུག\n",
            "you re out of sugar . => ཁྱོད ན གུ རམ་རྫོགས སོང ནུག\n",
            "am i dying ? => ང ཤི དེས ཡ\n",
            "we didn t order this . => ང་བཅས ཀྱིས འདི མཁོ་མངག མ འབད\n",
            "we accept all major credit and debit cards . => ང་བཅས ཀྱིས སོང་རྩིས དང དངུལ་ཚབ ཤོག་བྱང གཙོ་བོ ཚུ ག་ར ངོས་ལེན འབདཝ ཨིན\n",
            "that s not easy to do . => ཨ་ཕི དེ འབད ནི འཇམ་ཏོང་ཏོ མིན་འདུག\n",
            "lock your doors . => ཁྱོད་རའི སྒོ ཚུ ལྡེ་མིག རྐྱབ\n",
            "he took a deep breath . => ཁོ གིས བུང་རིངམོ ཅིག བཏང ཡི\n",
            "karma has been hoarding food . => ཀརྨ གིས བཟའ་འཐུང བསག པའི བསྒང འདུག\n",
            "have you eaten ? => ཁྱོད ལྟོ ཟ ཡི ག\n",
            "don t forget that . => དེ མ བརྗེད\n",
            "when are we going to leave ? => ང་བཅས ནམ འགྱོ ནི སྨོ\n",
            "i want a new knife . => ང གྱི་ཅུ གསརཔ ཅིག དགོ ནི\n",
            "i think it s impossible for him to solve the problem . => ང གིས བལྟ ད ཁོ གིས དཀའ་ངལ སེལ ཚུགས ནི དེ ལཱ་ཁག དྲགས འོང\n",
            "shall i carry your bag ? => ང གིས ཁྱོད ཀྱི ཕད་ཅུང འབག ག\n",
            "we took turns cleaning the room . => ང་བཅས ཀྱིས སྐོར་རྒྱབ སྦེ ཁང་མིག འཕྱག ཡི\n",
            "this is your share . => འདི ཁྱོད་རའི བགོ་བཤའ ཨིན་\n",
            "where are my parents ? => ངེའི ཕམ ཚུ ག་ཏེ ཡོད ག\n",
            "you d better not do it . => ཁྱོད ཀྱིས མ འབད་བ་ཅིན དྲག འོང\n",
            "did karma stay ? => ཀརྨ་སྡོད ཡི ཡ\n",
            "we ll make up for the loss . => ང་བཅས རྒུད ཕོག མི འདི བསུབ ནི\n",
            "this was purely due to volunteer efforts . => འ་ནཱི འདི་ཁས་བླངས་པ བརྩོན་ཤུགས རྐྱངམ་གཅིག ལས བརྟེན ཨིན\n",
            "what is your idea ? => ཁྱོད ཀྱི ཐབས་ཤེས ག་ཅི སྨོ\n",
            "this reminds me of you . => འ་ནཱི གིས ང ལུ ཁྱོད ཀྱི དྲན བརྡ་བྱིནམ མས\n",
            "in northern europe they used oil paint . => བྱང་ཕྱོགས ཀྱིཡུ་རོབ ནང མང་ཤོས རང་སྣུམ ལག་ལེན འཐབ ཨིན\n",
            "is karma absent today ? => ཀརྨ འདི ད་རེས མ འོང པས ག\n",
            "theyre always checking on him . => ཁོང ཨ་རྟག་ར ཁོ ཞིབ་དཔྱད འབདཝ མས\n",
            "i can play chopin . => ང གིས ཤོ པན རྩེ ཚུགས\n",
            "they re early . => ཁོང ཚུ ཧ་སག འགྱོ ནུག\n",
            "it could have been me . => འདི ང འབད རུང བཏུབ ནུག\n",
            "i can see you re frightened . => ང གིས ཁྱོད འདྲོག ནུག ཟེར ཤེས ཅི\n",
            "why do it this way ? => འདི ག་ཅི་སྦེ དེ་སྦེ འབད དགོཔ སྨོ\n",
            "how does policing work ? => ལྟ་རྟོག འབད མི འདི གིས ལཱ ག་དེ་སྦེ འབདཝ སྨོ\n",
            "i enjoy a challenge . => ང གིས ག་ཅི ཡང གདོང་ལན འབད ཚུགས\n",
            "the clock says two . => ཆུ་ཚོད གཉིས ཡར་སོང ནུག\n",
            "can you cater for my dietary requirements ? => ང གིས ཁ་སྲུང འབད ནིའི མཁོ་བྱད ཁྱོད ཀྱིས བསྐྱལ་བྱིན ན\n",
            "what is that made of ? => དེ ག་ཅི གིས བཟོ་བཟོཝ ཨིན་ན\n",
            "i live near the sea so i often go to the beach . => ང རྒྱ་མཚོ གི སྦོ་ལོགས་ཁར སྡོད ནི འདི་གིས འཕྲལ་འཕྲལ་ར མཚོའི མཐའ་མར འགྱོ ནི ཡོད\n",
            "i ll try to do that before i go home . => ང ཁྱིམ ནང མ འགྱོ བའི ཧེ་མ ལཱ དེ འབད ནི གི རྩིས་རྐྱབ འོང\n",
            "i obeyed . => ང གིས ཉན ཡི\n",
            "don t you remember what she told ? => ཁྱོད ཀྱིས མོ གིས སླབ མི མི དྲན མས ག\n",
            "i m looking for work . => ང ལཱ འཚོལ དོ\n",
            "i could probably convince karma not to do that . => ང གིས ཀརྨ ལུ དེ འབད ནི མི འོང ཟེར བའི གཅིག་འབདན ཡིད་ཆེས བསྐྱེད ཚུགསཔ འོང\n",
            "is karma drunk ? => ཀརྨ་ཆང བགྲང ནུག ཡ\n",
            "we kept the children quiet . => ང་བཅས ཀྱིས ཨ་ལོ ཚུ སྐད རྐྱབ མ བཅུག པར བཞག ཡི\n",
            "it s not a conversion anymore . => འདི ད་ལས་ཕར བསྒྱུར་བཅོས ཅིག མེན\n",
            "what kind of stone is this ? => ཨ་ནཱི ག་ཅི གི རྡོའི་རིགས ཨིན་ན\n",
            "we should have taken the schedule into consideration . => ང་བཅས ཀྱིས དུས་ཚོད རེའུ་མིག སེམས ཁར བཞག དགོ ནི སྡོད ནུག\n",
            "is your car new ? => ཁྱོད ཀྱི ཀཱར འདི གསརཔ ཨིན་ན\n",
            "still loved and sorely missed . => ད་ལྟོ ཡང བརྩེ་གདུང ཡོད དེ་ལས ཤུགས སྦེ ར དྲན མས\n",
            "he didn t get caught . => ཁོ བདའ མ ཟུན\n",
            "i didn t read that . => དེ ང གིས མ ལྷག\n",
            "the folder is empty . => ཡིག་གནས འདི སྟོང་པ ཨིན མས\n",
            "to weaken the empire , her enemies => རྒྱལ་ཆེན འདི སྟོབས ཉམས ནིའི དོན་ལས མོ གི དགྲ ༼\n",
            "i hope it s not true . => ང གིས བལྟ བ ཅིན འདི མི བདེནམ འོང\n",
            "who will help me ? => ང ལུ ག གིས ཆ་རོགས འབད འོང\n"
          ]
        }
      ],
      "source": [
        "# Checking the cleaned data\n",
        "for i in range(100):\n",
        "    print('%s => %s' % (cleanMtDocs[i, 0], cleanMtDocs[i, 1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLzYqV64_jGN"
      },
      "source": [
        "Starting the neural translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "aePuPUZy_cDJ"
      },
      "outputs": [],
      "source": [
        "# Creating the tokenizers\n",
        "# Function for creating tokenizers\n",
        "def createTokenizer(lines):\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(lines)\n",
        "    return tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bs5wWmsx_2aG",
        "outputId": "e872c60a-3d59-410b-98c0-737e04cd2000"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of english vocabulary 13163\n"
          ]
        }
      ],
      "source": [
        "# Create English Tokenizer\n",
        "eng_tokenizer = createTokenizer(cleanMtDocs[:,0])\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "print('Length of english vocabulary',eng_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnRU_DGR_743",
        "outputId": "2e7647ff-4662-4b8b-b135-f327fa8be653"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('i', 1),\n",
              " ('the', 2),\n",
              " ('you', 3),\n",
              " ('a', 4),\n",
              " ('is', 5),\n",
              " ('to', 6),\n",
              " ('it', 7),\n",
              " ('t', 8),\n",
              " ('s', 9),\n",
              " ('karma', 10)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Listing the first 10 items of the English tokenizer\n",
        "list(eng_tokenizer.word_index.items())[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvQvendbAB8E",
        "outputId": "f2ccc45d-59ad-415c-8243-8b9caaa5ff28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16958\n"
          ]
        }
      ],
      "source": [
        "# Create Dzongkha tokenizer\n",
        "dzo_tokenizer = createTokenizer(cleanMtDocs[:,1])\n",
        "# Defining Dzongkha Vocabulary\n",
        "dzo_vocab_size = len(dzo_tokenizer.word_index) + 1\n",
        "print(dzo_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjMZdNRYAS0G",
        "outputId": "a665a060-c334-446d-ae07-af7d06de1e82"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ང', 1),\n",
              " ('འདི', 2),\n",
              " ('གིས', 3),\n",
              " ('ལུ', 4),\n",
              " ('ཁྱོད', 5),\n",
              " ('ཨིན', 6),\n",
              " ('ཡི', 7),\n",
              " ('ཅིག', 8),\n",
              " ('མི', 9),\n",
              " ('འབད', 10),\n",
              " ('ནི', 11),\n",
              " ('གི', 12),\n",
              " ('མས', 13),\n",
              " ('ཁོ', 14),\n",
              " ('ག', 15),\n",
              " ('ང་བཅས', 16),\n",
              " ('མ', 17),\n",
              " ('ཀྱིས', 18),\n",
              " ('ནུག', 19),\n",
              " ('ཡོད', 20)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Listing the first 10 items of the English tokenizer\n",
        "list(dzo_tokenizer.word_index.items())[0:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZUBG-R0AbW8",
        "outputId": "ad5d52ea-4626-4481-f20c-90e1c1ec4bb0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6, 5, 7, 5, 7, 6, 6, 5, 6, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Create an empty list to store all english sentence lenghts\n",
        "len_english = []\n",
        "# Getting the length of all the English sentences\n",
        "[len_english.append(len(line.split())) for line in cleanMtDocs[:,0]]\n",
        "len_english[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kk6CeVEAlfL",
        "outputId": "eb84488f-eed2-4144-d0c7-b3786b532bae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 3, 12, 4, 8, 4, 6, 7, 4, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "len_Dzongkha = []\n",
        "# Getting the length of all the Dzongkha sentences\n",
        "[len_Dzongkha.append(len(line.split())) for line in cleanMtDocs[:,1]]\n",
        "len_Dzongkha[0:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcLSaZhmA4ry"
      },
      "source": [
        "Finding the optimimum sequence lengths."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8RllSLMAzDF",
        "outputId": "2479997d-ac3c-4490-98e5-bfe648515fdc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11.0"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# Find the quantile length\n",
        "engLength = np.quantile(len_english, .975)\n",
        "engLength"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xB_Sk7osA-gz",
        "outputId": "da571f46-3ccb-43a5-a317-cd0408163f97"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13.0"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# Find the quantile length\n",
        "dzoLength = np.quantile(len_Dzongkha, .975)\n",
        "dzoLength"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qt1CY7-BVwo"
      },
      "source": [
        "Encoding the sequences\n",
        "\n",
        "In this phase we will encode each of the sentences as integers in a sequence. Another task which needs to be done is to ensure that the lengths are standard. This is the reason we calcualated the maximum length of each sequence. We get the lengths standard by zero padding the sequences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GY0JaHIBCUz"
      },
      "outputs": [],
      "source": [
        "# Function for encoding and padding sequences\n",
        "\n",
        "def encode_sequences(tokenizer,length, lines):\n",
        "    # Sequences as integers\n",
        "    X = tokenizer.texts_to_sequences(lines)\n",
        "    # Padding the sentences with 0\n",
        "    X = pad_sequences(X,maxlen=length,padding='post')\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2stUDY8Bj44",
        "outputId": "988f8deb-0947-438c-8fe5-b53b619c934c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(45000, 2)\n",
            "(5000, 2)\n"
          ]
        }
      ],
      "source": [
        "# Preparing the train and test splits\n",
        "from sklearn.model_selection import train_test_split\n",
        "# split data into train and test set\n",
        "train, test = train_test_split(cleanMtDocs, test_size=0.1, random_state = 123)\n",
        "print(train.shape)\n",
        "print(test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYU_soblBt3I",
        "outputId": "2984de72-cf89-4742-819c-f766d12acb2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(45000, 13)\n",
            "(5000, 13)\n"
          ]
        }
      ],
      "source": [
        "# Creating the X variable for both train and test sets\n",
        "trainX = encode_sequences(dzo_tokenizer,int(dzoLength),train[:,1])\n",
        "testX = encode_sequences(dzo_tokenizer,int(dzoLength),test[:,1])\n",
        "print(trainX.shape)\n",
        "print(testX.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKqtAdCsBukY",
        "outputId": "ffba3bb8-9764-4a8b-db2d-ceac5c5a4889"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   1,    3,    2,  631,  250,    7,    0,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [ 482,   70, 5865,   31,  162,  470,    0,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [5612,    2,  168,   56,  385,   26,   11,  107,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   1,    3,   43,   26,  200,  145,    7,    0,    0,    0,    0,\n",
              "           0,    0],\n",
              "       [   9,   21,   92,    5,   63,   10,    9,    2,  467,   10,   62,\n",
              "          40,    0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# Displaying first 5 rows of the traininig set\n",
        "trainX[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dmqyNAvCC_n",
        "outputId": "58bb36c1-c309-4428-c487-6fe6c2e9cfd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(45000, 11)\n",
            "(5000, 11)\n"
          ]
        }
      ],
      "source": [
        "# Creating the Y variable both train and test\n",
        "trainY = encode_sequences(eng_tokenizer,int(engLength),train[:,0])\n",
        "testY = encode_sequences(eng_tokenizer,int(engLength),test[:,0])\n",
        "print(trainY.shape)\n",
        "print(testY.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Awn6V-WdCLW9"
      },
      "source": [
        "Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgRa_0HGCHCH"
      },
      "outputs": [],
      "source": [
        "def defineModel(src_vocab,tar_vocab,src_timesteps,tar_timesteps,n_units):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(src_vocab,n_units,input_length=src_timesteps,mask_zero=True))\n",
        "    model.add(LSTM(n_units))\n",
        "    model.add(RepeatVector(tar_timesteps))\n",
        "    model.add(LSTM(n_units,return_sequences=True))\n",
        "    model.add(TimeDistributed(Dense(tar_vocab,activation='softmax')))\n",
        "    # Compiling the model\n",
        "    model.compile(optimizer = 'adam',loss='sparse_categorical_crossentropy')\n",
        "    # Summarising the model\n",
        "    model.summary()\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKJA1IbTCa26",
        "outputId": "deb29794-c41d-4ff5-e7ad-05755436249b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 13, 256)           4341248   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 256)               525312    \n",
            "                                                                 \n",
            " repeat_vector (RepeatVector  (None, 11, 256)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 11, 256)           525312    \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 11, 13163)        3382891   \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,774,763\n",
            "Trainable params: 8,774,763\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = defineModel(dzo_vocab_size,eng_vocab_size,int(dzoLength),int(engLength),256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOxVlD9eC8vn",
        "outputId": "49e75fa7-0999-4853-9298-94d641673ccd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 2.88874, saving model to model1.h5\n",
            "4500/4500 - 61s - loss: 3.2507 - val_loss: 2.8887 - 61s/epoch - 14ms/step\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 2: val_loss improved from 2.88874 to 2.51237, saving model to model1.h5\n",
            "4500/4500 - 42s - loss: 2.6194 - val_loss: 2.5124 - 42s/epoch - 9ms/step\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 3: val_loss improved from 2.51237 to 2.34414, saving model to model1.h5\n",
            "4500/4500 - 42s - loss: 2.2400 - val_loss: 2.3441 - 42s/epoch - 9ms/step\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 4: val_loss improved from 2.34414 to 2.25961, saving model to model1.h5\n",
            "4500/4500 - 43s - loss: 1.9606 - val_loss: 2.2596 - 43s/epoch - 10ms/step\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 5: val_loss improved from 2.25961 to 2.21625, saving model to model1.h5\n",
            "4500/4500 - 41s - loss: 1.7204 - val_loss: 2.2163 - 41s/epoch - 9ms/step\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 6: val_loss improved from 2.21625 to 2.20381, saving model to model1.h5\n",
            "4500/4500 - 41s - loss: 1.5096 - val_loss: 2.2038 - 41s/epoch - 9ms/step\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 7: val_loss did not improve from 2.20381\n",
            "4500/4500 - 41s - loss: 1.3275 - val_loss: 2.2178 - 41s/epoch - 9ms/step\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 8: val_loss did not improve from 2.20381\n",
            "4500/4500 - 41s - loss: 1.1741 - val_loss: 2.2383 - 41s/epoch - 9ms/step\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 9: val_loss did not improve from 2.20381\n",
            "4500/4500 - 43s - loss: 1.0465 - val_loss: 2.2685 - 43s/epoch - 9ms/step\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 10: val_loss did not improve from 2.20381\n",
            "4500/4500 - 41s - loss: 0.9410 - val_loss: 2.2910 - 41s/epoch - 9ms/step\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 11: val_loss did not improve from 2.20381\n",
            "4500/4500 - 41s - loss: 0.8498 - val_loss: 2.3305 - 41s/epoch - 9ms/step\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 12: val_loss did not improve from 2.20381\n",
            "4500/4500 - 41s - loss: 0.7744 - val_loss: 2.3695 - 41s/epoch - 9ms/step\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 13: val_loss did not improve from 2.20381\n",
            "4500/4500 - 41s - loss: 0.7080 - val_loss: 2.4108 - 41s/epoch - 9ms/step\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 14: val_loss did not improve from 2.20381\n",
            "4500/4500 - 42s - loss: 0.6501 - val_loss: 2.4546 - 42s/epoch - 9ms/step\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 15: val_loss did not improve from 2.20381\n",
            "4500/4500 - 40s - loss: 0.5991 - val_loss: 2.4853 - 40s/epoch - 9ms/step\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 16: val_loss did not improve from 2.20381\n",
            "4500/4500 - 42s - loss: 0.5551 - val_loss: 2.5317 - 42s/epoch - 9ms/step\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 17: val_loss did not improve from 2.20381\n",
            "4500/4500 - 42s - loss: 0.5169 - val_loss: 2.5781 - 42s/epoch - 9ms/step\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 18: val_loss did not improve from 2.20381\n",
            "4500/4500 - 41s - loss: 0.4821 - val_loss: 2.6207 - 41s/epoch - 9ms/step\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 19: val_loss did not improve from 2.20381\n",
            "4500/4500 - 41s - loss: 0.4505 - val_loss: 2.6615 - 41s/epoch - 9ms/step\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 20: val_loss did not improve from 2.20381\n",
            "4500/4500 - 42s - loss: 0.4247 - val_loss: 2.6993 - 42s/epoch - 9ms/step\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 21: val_loss did not improve from 2.20381\n",
            "4500/4500 - 41s - loss: 0.4001 - val_loss: 2.7317 - 41s/epoch - 9ms/step\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 22: val_loss did not improve from 2.20381\n",
            "4500/4500 - 42s - loss: 0.3813 - val_loss: 2.7765 - 42s/epoch - 9ms/step\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 23: val_loss did not improve from 2.20381\n",
            "4500/4500 - 41s - loss: 0.3601 - val_loss: 2.8136 - 41s/epoch - 9ms/step\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 24: val_loss did not improve from 2.20381\n",
            "4500/4500 - 41s - loss: 0.3434 - val_loss: 2.8388 - 41s/epoch - 9ms/step\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 25: val_loss did not improve from 2.20381\n",
            "4500/4500 - 41s - loss: 0.3288 - val_loss: 2.8622 - 41s/epoch - 9ms/step\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 26: val_loss did not improve from 2.20381\n",
            "4500/4500 - 41s - loss: 0.3139 - val_loss: 2.8919 - 41s/epoch - 9ms/step\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 27: val_loss did not improve from 2.20381\n",
            "4500/4500 - 41s - loss: 0.3010 - val_loss: 2.9241 - 41s/epoch - 9ms/step\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 28: val_loss did not improve from 2.20381\n",
            "4500/4500 - 42s - loss: 0.2931 - val_loss: 2.9523 - 42s/epoch - 9ms/step\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 29: val_loss did not improve from 2.20381\n",
            "4500/4500 - 41s - loss: 0.2814 - val_loss: 2.9752 - 41s/epoch - 9ms/step\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 30: val_loss did not improve from 2.20381\n",
            "4500/4500 - 40s - loss: 0.2716 - val_loss: 3.0050 - 40s/epoch - 9ms/step\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 31: val_loss did not improve from 2.20381\n",
            "4500/4500 - 40s - loss: 0.2645 - val_loss: 3.0260 - 40s/epoch - 9ms/step\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 32: val_loss did not improve from 2.20381\n",
            "4500/4500 - 41s - loss: 0.2579 - val_loss: 3.0447 - 41s/epoch - 9ms/step\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 33: val_loss did not improve from 2.20381\n",
            "4500/4500 - 43s - loss: 0.2493 - val_loss: 3.0771 - 43s/epoch - 9ms/step\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 34: val_loss did not improve from 2.20381\n",
            "4500/4500 - 40s - loss: 0.2444 - val_loss: 3.0872 - 40s/epoch - 9ms/step\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 35: val_loss did not improve from 2.20381\n",
            "4500/4500 - 41s - loss: 0.2367 - val_loss: 3.1232 - 41s/epoch - 9ms/step\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 36: val_loss did not improve from 2.20381\n",
            "4500/4500 - 40s - loss: 0.2339 - val_loss: 3.1335 - 40s/epoch - 9ms/step\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 37: val_loss did not improve from 2.20381\n",
            "4500/4500 - 40s - loss: 0.2275 - val_loss: 3.1457 - 40s/epoch - 9ms/step\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 38: val_loss did not improve from 2.20381\n",
            "4500/4500 - 42s - loss: 0.2229 - val_loss: 3.1723 - 42s/epoch - 9ms/step\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 39: val_loss did not improve from 2.20381\n",
            "4500/4500 - 40s - loss: 0.2193 - val_loss: 3.1964 - 40s/epoch - 9ms/step\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 40: val_loss did not improve from 2.20381\n",
            "4500/4500 - 40s - loss: 0.2158 - val_loss: 3.2009 - 40s/epoch - 9ms/step\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 41: val_loss did not improve from 2.20381\n",
            "4500/4500 - 40s - loss: 0.2115 - val_loss: 3.2173 - 40s/epoch - 9ms/step\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 42: val_loss did not improve from 2.20381\n",
            "4500/4500 - 41s - loss: 0.2058 - val_loss: 3.2381 - 41s/epoch - 9ms/step\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 43: val_loss did not improve from 2.20381\n",
            "4500/4500 - 41s - loss: 0.2060 - val_loss: 3.2596 - 41s/epoch - 9ms/step\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 44: val_loss did not improve from 2.20381\n",
            "4500/4500 - 41s - loss: 0.2034 - val_loss: 3.2641 - 41s/epoch - 9ms/step\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 45: val_loss did not improve from 2.20381\n",
            "4500/4500 - 41s - loss: 0.2027 - val_loss: 3.2790 - 41s/epoch - 9ms/step\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 46: val_loss did not improve from 2.20381\n",
            "4500/4500 - 40s - loss: 0.1986 - val_loss: 3.2783 - 40s/epoch - 9ms/step\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 47: val_loss did not improve from 2.20381\n",
            "4500/4500 - 41s - loss: 0.1944 - val_loss: 3.2978 - 41s/epoch - 9ms/step\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 48: val_loss did not improve from 2.20381\n",
            "4500/4500 - 41s - loss: 0.1938 - val_loss: 3.3118 - 41s/epoch - 9ms/step\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 49: val_loss did not improve from 2.20381\n",
            "4500/4500 - 41s - loss: 0.1914 - val_loss: 3.3374 - 41s/epoch - 9ms/step\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 50: val_loss did not improve from 2.20381\n",
            "4500/4500 - 41s - loss: 0.1918 - val_loss: 3.3229 - 41s/epoch - 9ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe3bbb85ac0>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# Fitting the model\n",
        "checkpoint = ModelCheckpoint('model1.h5',monitor='val_loss',verbose=1,save_best_only=True,mode='min')\n",
        "model.fit(trainX,trainY,epochs=50,batch_size=10,validation_data=(testX,testY),callbacks=[checkpoint],verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nf1t4y0ODsm_"
      },
      "source": [
        "Inferencing and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SE0nt5ODhgy"
      },
      "outputs": [],
      "source": [
        "# loading the model from the best model saved\n",
        "model = load_model('model1.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MycGZafWDyMv",
        "outputId": "fcd1c712-ed68-44e3-c874-ebc0f92238ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 11, 13163)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# Generating the predictions\n",
        "prediction = model.predict(testX,verbose=0)\n",
        "prediction.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoLd95H9EDuU",
        "outputId": "a9746751-3918-4f3c-98c7-a2c76ac03cf1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([ 1, 25,  8, 41, 44,  1, 47,  0,  0,  0,  0]),\n",
              " array([  1,  23,   4,  61, 177,   0,   0,   0,   0,   0,   0]),\n",
              " array([ 2,  5, 16,  6,  6,  6,  0,  0,  0,  0,  0])]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "#Getting the prediction index along the last axis ( Vocabulary size axis)\n",
        "predIndex = [argmax(vector,axis = -1) for vector in prediction]\n",
        "predIndex[0:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJMTl4ReEJvb"
      },
      "outputs": [],
      "source": [
        "# Creating the reverse dictionary\n",
        "reverse_eng = eng_tokenizer.index_word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgkWHYPBET8q",
        "outputId": "48158a1c-8ab3-4b56-d7df-2d58a4d39ad3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i don t know how i go\n"
          ]
        }
      ],
      "source": [
        "# Converting the tokens to a sentence\n",
        "preds = []\n",
        "for pred in predIndex[0]:\n",
        "  if pred == 0:\n",
        "        continue \n",
        "  preds.append(reverse_eng[pred])  \n",
        "print(' '.join(preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41Z87wvREULx",
        "outputId": "6ae44265-521c-41bb-f8c5-b647539dc507"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i don t know how far\n"
          ]
        }
      ],
      "source": [
        "# Looking at the target sentence\n",
        "preds = []\n",
        "for pred in testY[0]:\n",
        "  if pred == 0:\n",
        "        continue \n",
        "  preds.append(reverse_eng[pred])  \n",
        "print(' '.join(preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsjIdfwmEUOL"
      },
      "outputs": [],
      "source": [
        "# Creating a function for converting sequences\n",
        "def Convertsequence(tokenizer,source):\n",
        "    target = list()\n",
        "    reverse_eng = tokenizer.index_word\n",
        "    for i in source:\n",
        "        if i == 0:\n",
        "            continue\n",
        "        target.append(reverse_eng[int(i)])\n",
        "    return ' '.join(target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLpHldkEEUQh"
      },
      "outputs": [],
      "source": [
        "# Function to generate predictions from source data\n",
        "def generatePredictions(model,tokenizer,data):\n",
        "    prediction = model.predict(data,verbose=0)\n",
        "    AllPreds = []\n",
        "    for i in range(len(prediction)):\n",
        "        predIndex = [argmax(prediction[i, :, :], axis=-1)][0]\n",
        "        target = Convertsequence(tokenizer,predIndex)\n",
        "        AllPreds.append(target)\n",
        "    return AllPreds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpdScTZjEUS3"
      },
      "outputs": [],
      "source": [
        "# Generate predictions\n",
        "predSent = generatePredictions(model,eng_tokenizer,testX[0:20,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyOpKG-SEUVc",
        "outputId": "8a539b3f-cc04-4d38-d6dd-7fa235e259a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original sentence : ['i don t know how far'] :: Prediction : ['i don t know how i go']\n",
            "Original sentence : ['i m a nice guy'] :: Prediction : ['i m a good man']\n",
            "Original sentence : ['the songs are divided for easy consult'] :: Prediction : ['the is was to to to']\n",
            "Original sentence : ['i had a breakdown'] :: Prediction : ['i was dumbfounded']\n",
            "Original sentence : ['he likes animals'] :: Prediction : ['he likes animals']\n",
            "Original sentence : ['i forgot you were listening'] :: Prediction : ['i forgot you you retired']\n",
            "Original sentence : ['are you ready for halloween'] :: Prediction : ['are you ready to to']\n",
            "Original sentence : ['all of our calls are free and confidential'] :: Prediction : ['our our our our our our']\n",
            "Original sentence : ['i ll get the check'] :: Prediction : ['i ll pay the']\n",
            "Original sentence : ['i ll destroy it'] :: Prediction : ['i ll arrange it']\n",
            "Original sentence : ['i laughed at his joke'] :: Prediction : ['i forgave his his']\n",
            "Original sentence : ['use this'] :: Prediction : ['take this']\n",
            "Original sentence : ['this is when we started on the scout for some great'] :: Prediction : ['it s a a of of of']\n",
            "Original sentence : ['i m looking for work'] :: Prediction : ['i m looking to']\n",
            "Original sentence : ['i love nature'] :: Prediction : ['i like music']\n",
            "Original sentence : ['give me a tissue'] :: Prediction : ['give me a example']\n",
            "Original sentence : ['where s the original'] :: Prediction : ['where s the']\n",
            "Original sentence : ['that s a man s job'] :: Prediction : ['that s a pretty']\n",
            "Original sentence : ['i met an old woman'] :: Prediction : ['i made a a']\n",
            "Original sentence : ['you ll do exactly as i say'] :: Prediction : ['what do what what say do']\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(testY[0:20])):\n",
        "    targetY = Convertsequence(eng_tokenizer,testY[i:i+1][0])\n",
        "    print(\"Original sentence : {} :: Prediction : {}\".format([targetY],[predSent[i]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce44i0rOEtr3"
      },
      "source": [
        "Predicting on your own sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p80UeAbjEtYo"
      },
      "outputs": [],
      "source": [
        "def cleanInput(lines):\n",
        "    cleanSent = []\n",
        "    cleanDocs = list()\n",
        "    for docs in lines.split():\n",
        "        line=str(docs)\n",
        "        line = re.sub(r'་\\s*[& ]', ' ',line)\n",
        "        line=re.sub(r\"\\s*།\\s*$\", '', line)\n",
        "        line=re.sub(r'\\s#\\s',' ',line)\n",
        "        cleanDocs.append(line)\n",
        "    cleanSent.append(' '.join(cleanDocs))\n",
        "    return array(cleanSent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZDKTIeMEUXD"
      },
      "outputs": [],
      "source": [
        "# Trying different input sentences\n",
        "inputSentence = 'གྲུ་ འདི་ ཆུ་ ནང་ ཐིམ་ དེས །'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATrLA2EDEUZE",
        "outputId": "e2feddf2-fb30-4d39-dedc-06f5df370842"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['གྲུ་ འདི་ ཆུ་ ནང་ ཐིམ་ དེས '], dtype='<U27')"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "# Clean the input sentence\n",
        "cleanText = cleanInput(inputSentence)\n",
        "cleanText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2NbtAJrEUcf",
        "outputId": "4661a2a7-0785-4046-e67c-73ef106889ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3592,   83,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "# Encode the inputsentence as sequence of integers\n",
        "seq1 = encode_sequences(dzo_tokenizer,int(dzoLength),cleanText)\n",
        "seq1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdGM04jPFJZd",
        "outputId": "e4041eb1-19a4-4a4a-ec7f-69ddee587244"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original sentence : ['གྲུ་ འདི་ ཆུ་ ནང་ ཐིམ་ དེས '] :: Prediction : ['this is a']\n"
          ]
        }
      ],
      "source": [
        "# Generate the prediction\n",
        "predSent = generatePredictions(model,eng_tokenizer,seq1)\n",
        "\n",
        "print(\"Original sentence : {} :: Prediction : {}\".format([cleanText[0]],predSent))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpa8o4K7FLyi",
        "outputId": "e66e7b2f-a9fc-4d76-e32d-783ce4ecf280"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original sentence : ['བྱི་ལི་ འདི་ ཉལ་ ནུག '] :: Prediction : ['this is a']\n",
            "Original sentence : ['འདི་ མོ་ གིས་ ཤེས '] :: Prediction : ['she knows know know']\n"
          ]
        }
      ],
      "source": [
        "inputSentence1 ='བྱི་ལི་ འདི་ ཉལ་ ནུག །' \n",
        "inputSentence2 ='འདི་ མོ་ གིས་ ཤེས །' \n",
        "\n",
        "for sentence in [inputSentence1,inputSentence2]:\n",
        "  cleanText = cleanInput(sentence)\n",
        "  seq1 = encode_sequences(dzo_tokenizer,int(dzoLength),cleanText)\n",
        "  # Generate the prediction\n",
        "  predSent = generatePredictions(model,eng_tokenizer,seq1)\n",
        "\n",
        "  print(\"Original sentence : {} :: Prediction : {}\".format([cleanText[0]],predSent))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAU_MOPqU1la",
        "outputId": "3f5b6017-593c-4484-a92d-be9cc41113c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: eng_tokenizer.pkl\n",
            "Saved: eng_vocab_size.pkl\n",
            "Saved: dzo_tokenizer.pkl\n",
            "Saved: dzo_vocab_size.pkl\n",
            "Saved: trainX.pkl\n",
            "Saved: trainY.pkl\n",
            "Saved: testX.pkl\n",
            "Saved: testY.pkl\n",
            "Saved: len_english.pkl\n",
            "Saved: len_Dzongkha.pkl\n"
          ]
        }
      ],
      "source": [
        "### Saving the tokenizers and other variables as pickle files\n",
        "save_data(eng_tokenizer,'eng_tokenizer.pkl')\n",
        "save_data(eng_vocab_size,'eng_vocab_size.pkl')\n",
        "save_data(dzo_tokenizer,'dzo_tokenizer.pkl')\n",
        "save_data(dzo_vocab_size,'dzo_vocab_size.pkl')\n",
        "save_data(trainX,'trainX.pkl')\n",
        "save_data(trainY,'trainY.pkl')\n",
        "save_data(testX,'testX.pkl')\n",
        "save_data(testY,'testY.pkl')\n",
        "save_data(engLength,'len_english.pkl')\n",
        "save_data(dzoLength,'len_Dzongkha.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-UnnmWmYUE4C"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "1rvntmQz_7wo_R_61WJcwLoqvp9aI2mHC",
      "authorship_tag": "ABX9TyNMZJggE+uLzkXy2gDkXteH",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}